{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.chains import LLMMathChain, LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.agents import Tool, initialize_agent\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(openai_api_key=os.getenv(\"OPENAI_API_KEY\"), \n",
    "                openai_api_base=\"https://free-cdo.openai.azure.com/openai/deployments/cod-free-gpt4o/chat/completions?api-version=2024-02-15-preview\",\n",
    "                openai_api_version=\"2024-02-15-preview\",\n",
    "                openai_api_type=\"azure\",\n",
    "                temperature=0.2\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia = WikipediaAPIWrapper()\n",
    "\n",
    "wikipedia_tool = Tool(\n",
    "                    name=\"Wikipedia\",\n",
    "                    func=wikipedia.run,\n",
    "\t                description=\"A useful tool for searching the Internet to find information on world events, \\\n",
    "                               issues, dates, years, etc. Worth using for general topics. Use precise questions.\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_chain = LLMMathChain.from_llm(llm=llm)\n",
    "\n",
    "math_tool = Tool.from_function(name=\"Calculator\",\n",
    "                func=problem_chain.run,\n",
    "                description=\"Useful for when you need to answer questions about math. \\\n",
    "                    This tool is only for math questions and nothing else. Only inputmath expressions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_problem_template = \"\"\"You are a reasoning agent tasked with solving \n",
    "the user's logic-based questions. Logically arrive at the solution, and be \n",
    "factual. In your answers, clearly detail the steps involved and give the \n",
    "final answer. Provide the response in bullet points. \n",
    "Question {question} Answer\"\"\"\n",
    "\n",
    "math_assistant_prompt = PromptTemplate(input_variables=[\"question\"],\n",
    "                                       template=word_problem_template\n",
    "                                       )\n",
    "word_problem_chain = LLMChain(llm=llm,\n",
    "                              prompt=math_assistant_prompt)\n",
    "\n",
    "word_problem_tool = Tool.from_function(name=\"Reasoning Tool\",\n",
    "                                       func=word_problem_chain.run,\n",
    "                                       description=\"Useful for when you need to answer logic-based/reasoning questions.\",\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(\n",
    "            tools=[wikipedia_tool, math_tool, word_problem_tool],\n",
    "            llm=llm,\n",
    "            agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            verbose=True,\n",
    "            handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "print(agent.invoke({\"input\": \"I have 3 apples and 4 oranges. I give half of my oranges \\\n",
    "               away and buy two dozen new ones, alongwith three packs of \\\n",
    "               strawberries. Each pack of strawberry has 30 strawberries. \\\n",
    "               How  many total pieces of fruit do I have at the end?\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unrelated tests for web scraping..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import AsyncChromiumLoader\n",
    "from langchain_community.document_transformers import BeautifulSoupTransformer\n",
    "\n",
    "# Load HTML\n",
    "loader = AsyncChromiumLoader([\"https://www.wsj.com\"])\n",
    "html = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform\n",
    "bs_transformer = BeautifulSoupTransformer()\n",
    "docs_transformed = bs_transformer.transform_documents(html, tags_to_extract=[\"span\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result\n",
    "docs_transformed[0].page_content[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import AsyncHtmlLoader\n",
    "\n",
    "urls = [\"https://www.espn.com\", \"https://lilianweng.github.io/posts/2023-06-23-agent/\"]\n",
    "\n",
    "loader = AsyncHtmlLoader(urls)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_transformers import Html2TextTransformer\n",
    "\n",
    "html2text = Html2TextTransformer()\n",
    "docs_transformed = html2text.transform_documents(docs)\n",
    "docs_transformed[0].page_content[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import BaseTool\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(openai_api_key=os.getenv(\"OPENAI_API_KEY\"), \n",
    "                openai_api_base=\"https://free-cdo.openai.azure.com/openai/deployments/cod-free-gpt4o/chat/completions?api-version=2024-02-15-preview\",\n",
    "                openai_api_version=\"2024-02-15-preview\",\n",
    "                openai_api_type=\"azure\",\n",
    "                temperature=0.2\n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebBrowserTool(BaseTool):\n",
    "    name = \"Web Browser\"\n",
    "    description = \"A tool for browsing and extracting information from websites.\"\n",
    "\n",
    "    def _run(self, url: str) -> str:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Extract text content from the page\n",
    "        text_content = soup.get_text(separator=' ', strip=True)\n",
    "        \n",
    "        # Limit the content to a reasonable length\n",
    "        return text_content[:5000]  # Adjust as needed\n",
    "\n",
    "    def _arun(self, url: str) -> str:\n",
    "        # For asynchronous operations\n",
    "        raise NotImplementedError(\"WebBrowserTool does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "\n",
    "web_browser = WebBrowserTool()\n",
    "tools = load_tools([\"llm-math\"], llm=llm) + [web_browser]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the agent to browse a website and extract information\n",
    "result = agent.run(\"Summarize the content of https://www.example.com\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(\n",
    "            tools=[wikipedia_tool, math_tool, word_problem_tool, web_browser],\n",
    "            llm=llm,\n",
    "            agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            verbose=True,\n",
    "            handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "# result = agent.invoke({\"input\": \"I have 3 apples and 4 oranges. I give half of my oranges \\\n",
    "#                away and buy two dozen new ones, alongwith three packs of \\\n",
    "#                strawberries. Each pack of strawberry has 30 strawberries. \\\n",
    "#                How  many total pieces of fruit do I have at the end?\"})\n",
    "# print(result)\n",
    "\n",
    "result = agent.run(\"Summarize the content of https://www.example.com\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import html2text\n",
    "\n",
    "def scrape_and_convert_to_markdown(url):\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Remove unwanted elements (optional)\n",
    "        for script in soup([\"script\", \"style\"]):\n",
    "            script.decompose()\n",
    "        \n",
    "        # Convert HTML to Markdown\n",
    "        h = html2text.HTML2Text()\n",
    "        h.ignore_links = False\n",
    "        h.ignore_images = False\n",
    "        markdown_content = h.handle(str(soup))\n",
    "        \n",
    "        return markdown_content\n",
    "    else:\n",
    "        return f\"Failed to retrieve the webpage. Status code: {response.status_code}\"\n",
    "\n",
    "# Example usage\n",
    "url = \"https://www.vantage.sh/blog/azure-openai-vs-amazon-bedrock-cost\"\n",
    "\n",
    "markdown_result = scrape_and_convert_to_markdown(url)\n",
    "print(markdown_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, save the markdown content to a file\n",
    "with open(\"output.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(markdown_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up a tool with the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebScraperMarkdownTool(BaseTool):\n",
    "    \n",
    "    name = \"Web Scraper to Markdown\"\n",
    "    description = \"Useful for scraping content from a website and converting it to markdown format. Input should be a valid URL.\"\n",
    "\n",
    "    def _run(self, url: str) -> str:\n",
    "        try:\n",
    "            # Send a GET request to the URL\n",
    "            response = requests.get(url)\n",
    "            \n",
    "            # Check if the request was successful\n",
    "            if response.status_code == 200:\n",
    "                # Parse the HTML content\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                \n",
    "                # Remove unwanted elements (optional)\n",
    "                for script in soup([\"script\", \"style\"]):\n",
    "                    script.decompose()\n",
    "                \n",
    "                # Convert HTML to Markdown\n",
    "                h = html2text.HTML2Text()\n",
    "                h.ignore_links = False\n",
    "                h.ignore_images = False\n",
    "                markdown_content = h.handle(str(soup))\n",
    "                \n",
    "                return markdown_content\n",
    "            else:\n",
    "                return f\"Failed to retrieve the webpage. Status code: {response.status_code}\"\n",
    "        except Exception as e:\n",
    "            return f\"An error occurred: {str(e)}\"\n",
    "\n",
    "    def _arun(self, url: str) -> str:\n",
    "        # This tool doesn't support async operations\n",
    "        raise NotImplementedError(\"WebScraperMarkdownTool does not support async\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "# Create an instance of our custom tool\n",
    "web_scraper_tool = WebScraperMarkdownTool()\n",
    "\n",
    "# Initialize the agent with our custom tool\n",
    "tools = [web_scraper_tool]\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=False)\n",
    "\n",
    "# Use the agent\n",
    "result = agent.run(\"Get the Claude Sonnet price for 1000 output token, see https://www.vantage.sh/blog/azure-openai-vs-amazon-bedrock-cost\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quick_start",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
